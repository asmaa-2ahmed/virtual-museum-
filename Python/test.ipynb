{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AsmaA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AsmaA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server listening on 127.0.0.1:5000\n",
      "Connection from ('127.0.0.1', 53821)\n",
      "Received query: who is ramesses?\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import PyPDF2\n",
    "import nltk\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Step 1: Extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            text = ''.join([page.extract_text() for page in reader.pages])\n",
    "            return text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text from PDF: {e}\"\n",
    "\n",
    "# Step 2: Chunk text into smaller pieces\n",
    "def chunk_text(document_text, chunk_size=500, overlap=50):\n",
    "    if not document_text:\n",
    "        return []\n",
    "    chunks = []\n",
    "    for i in range(0, len(document_text), chunk_size - overlap):\n",
    "        chunk = document_text[i:i + chunk_size]\n",
    "        if not chunk.endswith(('.', '!', '?')):\n",
    "            last_period = chunk.rfind('.')\n",
    "            chunk = chunk[:last_period + 1] if last_period != -1 else chunk\n",
    "        chunks.append(chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "# Step 3: Create embeddings\n",
    "def create_embeddings(chunks):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(chunks)\n",
    "    return embeddings, model\n",
    "\n",
    "# Step 4: Build FAISS index\n",
    "def create_faiss_index(embeddings):\n",
    "    embeddings = np.array(embeddings).astype('float32')\n",
    "    faiss.normalize_L2(embeddings)\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "# Step 5: Retrieve the most relevant chunk\n",
    "def retrieve_relevant_chunk(query, model, index, chunks):\n",
    "    query_embedding = model.encode([query]).astype('float32')\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    distances, indices = index.search(query_embedding, k=1)\n",
    "\n",
    "    if distances[0][0] > 0.8:  # Threshold for match quality\n",
    "        return \"No relevant information found for your query.\"\n",
    "\n",
    "    return chunks[indices[0][0]]\n",
    "\n",
    "# Server Functionality\n",
    "def start_server(pdf_path):\n",
    "    document_text = extract_text_from_pdf(pdf_path)\n",
    "    if not document_text or \"Error\" in document_text:\n",
    "        return f\"Error: {document_text}\"\n",
    "\n",
    "    chunks = chunk_text(document_text)\n",
    "    if not chunks:\n",
    "        return \"The PDF contains no readable text.\"\n",
    "\n",
    "    embeddings, model = create_embeddings(chunks)\n",
    "    index = create_faiss_index(embeddings)\n",
    "\n",
    "    # Socket setup\n",
    "    host = \"127.0.0.1\"\n",
    "    port = 5000\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_socket.bind((host, port))\n",
    "    server_socket.listen(1)\n",
    "    print(f\"Server listening on {host}:{port}\")\n",
    "\n",
    "    while True:\n",
    "        client_socket, address = server_socket.accept()\n",
    "        print(f\"Connection from {address}\")\n",
    "\n",
    "        # Receive query\n",
    "        query = client_socket.recv(1024).decode(\"utf-8\").strip()\n",
    "        print(f\"Received query: {query}\")\n",
    "\n",
    "        if query.lower() == \"exit\":\n",
    "            response = \"Goodbye!\"\n",
    "            client_socket.send(response.encode(\"utf-8\"))\n",
    "            client_socket.close()\n",
    "            break\n",
    "\n",
    "        # Get relevant chunk\n",
    "        response = retrieve_relevant_chunk(query, model, index, chunks)\n",
    "        client_socket.send(response.encode(\"utf-8\"))\n",
    "\n",
    "        client_socket.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"DatasetNLP.pdf\"  # Replace with the actual path to your PDF\n",
    "    start_server(pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AsmaA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1006)>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server listening on 127.0.0.1:5000\n",
      "Waiting for a client connection...\n",
      "Connection established with ('127.0.0.1', 52746)\n",
      "Received query: who is ramesses?\n",
      "Received query: who is ramesses?\n",
      "Waiting for a client connection...\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import PyPDF2\n",
    "import nltk\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Step 1: Extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            text = ''.join([page.extract_text() for page in reader.pages])\n",
    "            return text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text from PDF: {e}\"\n",
    "\n",
    "# Step 2: Chunk text into smaller pieces\n",
    "def chunk_text(document_text, chunk_size=500, overlap=50):\n",
    "    chunks = []\n",
    "    for i in range(0, len(document_text), chunk_size - overlap):\n",
    "        chunk = document_text[i:i + chunk_size]\n",
    "        if not chunk.endswith(('.', '!', '?')):\n",
    "            last_period = chunk.rfind('.')\n",
    "            chunk = chunk[:last_period + 1] if last_period != -1 else chunk\n",
    "        chunks.append(chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "# Step 3: Create embeddings\n",
    "def create_embeddings(chunks):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(chunks)\n",
    "    return embeddings, model\n",
    "\n",
    "# Step 4: Build FAISS index\n",
    "def create_faiss_index(embeddings):\n",
    "    embeddings = np.array(embeddings).astype('float32')\n",
    "    faiss.normalize_L2(embeddings)\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "# Step 5: Retrieve the most relevant chunk\n",
    "def retrieve_relevant_chunk(query, model, index, chunks):\n",
    "    query_embedding = model.encode([query]).astype('float32')\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    distances, indices = index.search(query_embedding, k=1)\n",
    "\n",
    "    if distances[0][0] > 0.8:  # Threshold for match quality\n",
    "        return \"No relevant information found for your query.\"\n",
    "\n",
    "    return chunks[indices[0][0]]\n",
    "\n",
    "# Server Functionality\n",
    "def start_server(pdf_path):\n",
    "    document_text = extract_text_from_pdf(pdf_path)\n",
    "    if not document_text or \"Error\" in document_text:\n",
    "        print(f\"Error: {document_text}\")\n",
    "        return\n",
    "\n",
    "    chunks = chunk_text(document_text)\n",
    "    if not chunks:\n",
    "        print(\"The PDF contains no readable text.\")\n",
    "        return\n",
    "\n",
    "    embeddings, model = create_embeddings(chunks)\n",
    "    index = create_faiss_index(embeddings)\n",
    "\n",
    "    # Socket setup\n",
    "    host = \"127.0.0.1\"\n",
    "    port = 5000\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_socket.bind((host, port))\n",
    "    server_socket.listen(1)\n",
    "    print(f\"Server listening on {host}:{port}\")\n",
    "\n",
    "    while True:\n",
    "        print(\"Waiting for a client connection...\")\n",
    "        client_socket, address = server_socket.accept()\n",
    "        print(f\"Connection established with {address}\")\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                # Receive query\n",
    "                query = client_socket.recv(1024).decode(\"utf-8\").strip()\n",
    "                if not query:\n",
    "                    break  # Handle empty query or client disconnection\n",
    "                print(f\"Received query: {query}\")\n",
    "\n",
    "                if query.lower() == \"exit\":\n",
    "                    response = \"Goodbye!\"\n",
    "                    client_socket.send(response.encode(\"utf-8\"))\n",
    "                    print(f\"Connection with {address} closed.\")\n",
    "                    break\n",
    "\n",
    "                # Get relevant chunk\n",
    "                response = retrieve_relevant_chunk(query, model, index, chunks)\n",
    "                client_socket.send(response.encode(\"utf-8\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error during communication: {e}\")\n",
    "        finally:\n",
    "            client_socket.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"DatasetNLP.pdf\"  # Replace with your actual PDF file path\n",
    "    start_server(pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AsmaA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server listening on 127.0.0.1:1234\n",
      "Waiting for a client connection...\n",
      "Connection established with ('127.0.0.1', 55884)\n",
      "Received query: who is ramesses?\n",
      "Text Response: 1. Ramesses III  \n",
      "Historical Context  \n",
      "• Dynasty and Time Period : Ramesses III was the second pharaoh of the 20th Dynasty (1186 –1155 \n",
      "BCE), during a time of increasing external threats and internal instability.  \n",
      "• Major Accomplishments :  \n",
      "o Defensive Campaigns : Successfully repelled invasions by the Sea Peoples, securing \n",
      "Egypt’s borders. This victory is recorded in the temple of Medinet Habu, where detailed \n",
      "battle reliefs portray the conflict.\n",
      "Text response sent.\n",
      "Notifying client about incoming audio.\n",
      "Audio response sent.\n",
      "Received query: who is ramesses?\n",
      "Text Response: 1. Ramesses III  \n",
      "Historical Context  \n",
      "• Dynasty and Time Period : Ramesses III was the second pharaoh of the 20th Dynasty (1186 –1155 \n",
      "BCE), during a time of increasing external threats and internal instability.  \n",
      "• Major Accomplishments :  \n",
      "o Defensive Campaigns : Successfully repelled invasions by the Sea Peoples, securing \n",
      "Egypt’s borders. This victory is recorded in the temple of Medinet Habu, where detailed \n",
      "battle reliefs portray the conflict.\n",
      "Text response sent.\n",
      "Notifying client about incoming audio.\n",
      "Audio response sent.\n",
      "Received query: who is ?\n",
      "Text Response: No relevant information found for your query.\n",
      "Text response sent.\n",
      "Notifying client about incoming audio.\n",
      "Audio response sent.\n",
      "Received query: who is ?\n",
      "Text Response: No relevant information found for your query.\n",
      "Text response sent.\n",
      "Notifying client about incoming audio.\n",
      "Audio response sent.\n",
      "Received query: who is ?\n",
      "Text Response: No relevant information found for your query.\n",
      "Text response sent.\n",
      "Notifying client about incoming audio.\n",
      "Audio response sent.\n",
      "Received query: who is ?\n",
      "Text Response: No relevant information found for your query.\n",
      "Text response sent.\n",
      "Notifying client about incoming audio.\n",
      "Audio response sent.\n",
      "Received query: exit\n",
      "Connection with ('127.0.0.1', 55884) closed.\n",
      "Waiting for a client connection...\n",
      "Connection established with ('127.0.0.1', 55908)\n",
      "Received query: what ais\n",
      "Text Response: No relevant information found for your query.\n",
      "Text response sent.\n",
      "Notifying client about incoming audio.\n",
      "Audio response sent.\n",
      "Received query: what ais\n",
      "Text Response: No relevant information found for your query.\n",
      "Text response sent.\n",
      "Notifying client about incoming audio.\n",
      "Audio response sent.\n",
      "Received query: who is ramesses?\n",
      "Text Response: 1. Ramesses III  \n",
      "Historical Context  \n",
      "• Dynasty and Time Period : Ramesses III was the second pharaoh of the 20th Dynasty (1186 –1155 \n",
      "BCE), during a time of increasing external threats and internal instability.  \n",
      "• Major Accomplishments :  \n",
      "o Defensive Campaigns : Successfully repelled invasions by the Sea Peoples, securing \n",
      "Egypt’s borders. This victory is recorded in the temple of Medinet Habu, where detailed \n",
      "battle reliefs portray the conflict.\n",
      "Text response sent.\n",
      "Notifying client about incoming audio.\n",
      "Audio response sent.\n",
      "Received query: who is ramesses?\n",
      "Text Response: 1. Ramesses III  \n",
      "Historical Context  \n",
      "• Dynasty and Time Period : Ramesses III was the second pharaoh of the 20th Dynasty (1186 –1155 \n",
      "BCE), during a time of increasing external threats and internal instability.  \n",
      "• Major Accomplishments :  \n",
      "o Defensive Campaigns : Successfully repelled invasions by the Sea Peoples, securing \n",
      "Egypt’s borders. This victory is recorded in the temple of Medinet Habu, where detailed \n",
      "battle reliefs portray the conflict.\n",
      "Text response sent.\n",
      "Notifying client about incoming audio.\n",
      "Audio response sent.\n",
      "Received query: exit\n",
      "Connection with ('127.0.0.1', 55908) closed.\n",
      "Waiting for a client connection...\n",
      "Connection established with ('127.0.0.1', 55915)\n",
      "Received query: who is ramesses?\n",
      "Text Response: 1. Ramesses III  \n",
      "Historical Context  \n",
      "• Dynasty and Time Period : Ramesses III was the second pharaoh of the 20th Dynasty (1186 –1155 \n",
      "BCE), during a time of increasing external threats and internal instability.  \n",
      "• Major Accomplishments :  \n",
      "o Defensive Campaigns : Successfully repelled invasions by the Sea Peoples, securing \n",
      "Egypt’s borders. This victory is recorded in the temple of Medinet Habu, where detailed \n",
      "battle reliefs portray the conflict.\n",
      "Text response sent.\n",
      "Notifying client about incoming audio.\n",
      "Audio response sent.\n",
      "Received query: who is ramesses?\n",
      "Text Response: 1. Ramesses III  \n",
      "Historical Context  \n",
      "• Dynasty and Time Period : Ramesses III was the second pharaoh of the 20th Dynasty (1186 –1155 \n",
      "BCE), during a time of increasing external threats and internal instability.  \n",
      "• Major Accomplishments :  \n",
      "o Defensive Campaigns : Successfully repelled invasions by the Sea Peoples, securing \n",
      "Egypt’s borders. This victory is recorded in the temple of Medinet Habu, where detailed \n",
      "battle reliefs portray the conflict.\n",
      "Text response sent.\n",
      "Notifying client about incoming audio.\n",
      "Audio response sent.\n",
      "Received query: who is thotmos?\n",
      "Text Response: No relevant information found for your query.\n",
      "Text response sent.\n",
      "Notifying client about incoming audio.\n",
      "Audio response sent.\n",
      "Received query: who is thotmos?\n",
      "Text Response: No relevant information found for your query.\n",
      "Text response sent.\n",
      "Notifying client about incoming audio.\n",
      "Audio response sent.\n",
      "Waiting for a client connection...\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import PyPDF2\n",
    "import nltk\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pyttsx3\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Step 1: Extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            text = ''.join([page.extract_text() for page in reader.pages])\n",
    "            return text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text from PDF: {e}\"\n",
    "\n",
    "# Step 2: Chunk text into smaller pieces\n",
    "def chunk_text(document_text, chunk_size=500, overlap=50):\n",
    "    chunks = []\n",
    "    for i in range(0, len(document_text), chunk_size - overlap):\n",
    "        chunk = document_text[i:i + chunk_size]\n",
    "        if not chunk.endswith(('.', '!', '?')):\n",
    "            last_period = chunk.rfind('.')\n",
    "            chunk = chunk[:last_period + 1] if last_period != -1 else chunk\n",
    "        chunks.append(chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "# Step 3: Create embeddings\n",
    "def create_embeddings(chunks):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(chunks)\n",
    "    return embeddings, model\n",
    "\n",
    "# Step 4: Build FAISS index\n",
    "def create_faiss_index(embeddings):\n",
    "    embeddings = np.array(embeddings).astype('float32')\n",
    "    faiss.normalize_L2(embeddings)\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "# Step 5: Retrieve the most relevant chunk\n",
    "def retrieve_relevant_chunk(query, model, index, chunks):\n",
    "    query_embedding = model.encode([query]).astype('float32')\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    distances, indices = index.search(query_embedding, k=1)\n",
    "\n",
    "    if distances[0][0] > 0.8:  # Threshold for match quality\n",
    "        return \"No relevant information found for your query.\"\n",
    "\n",
    "    return chunks[indices[0][0]]\n",
    "\n",
    "# Step 6: Synthesize text-to-speech (TTS) and save audio\n",
    "def synthesize_speech(text, output_file=\"output.wav\"):\n",
    "    try:\n",
    "        engine = pyttsx3.init()\n",
    "        engine.save_to_file(text, output_file)\n",
    "        engine.runAndWait()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during speech synthesis: {e}\")\n",
    "        return None\n",
    "    return output_file\n",
    "\n",
    "# Server Functionality\n",
    "# Server Functionality\n",
    "def start_server(pdf_path):\n",
    "    document_text = extract_text_from_pdf(pdf_path)\n",
    "    if not document_text or \"Error\" in document_text:\n",
    "        print(f\"Error: {document_text}\")\n",
    "        return\n",
    "\n",
    "    chunks = chunk_text(document_text)\n",
    "    if not chunks:\n",
    "        print(\"The PDF contains no readable text.\")\n",
    "        return\n",
    "\n",
    "    embeddings, model = create_embeddings(chunks)\n",
    "    index = create_faiss_index(embeddings)\n",
    "\n",
    "    # Socket setup\n",
    "    host = \"127.0.0.1\"\n",
    "    port = 1234\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_socket.bind((host, port))\n",
    "    server_socket.listen(1)\n",
    "    print(f\"Server listening on {host}:{port}\")\n",
    "\n",
    "    while True:\n",
    "        print(\"Waiting for a client connection...\")\n",
    "        client_socket, address = server_socket.accept()\n",
    "        print(f\"Connection established with {address}\")\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                # Receive query\n",
    "                query = client_socket.recv(1024).decode(\"utf-8\").strip()\n",
    "                if not query:\n",
    "                    break  # Handle empty query or client disconnection\n",
    "                print(f\"Received query: {query}\")\n",
    "\n",
    "                if query.lower() == \"exit\":\n",
    "                    response = \"Goodbye!\"\n",
    "                    client_socket.send(response.encode(\"utf-8\"))\n",
    "                    print(f\"Connection with {address} closed.\")\n",
    "                    break\n",
    "\n",
    "                # Get relevant chunk\n",
    "                text_response = retrieve_relevant_chunk(query, model, index, chunks)\n",
    "                print(f\"Text Response: {text_response}\")\n",
    "\n",
    "                # Step 1: Send text response\n",
    "                client_socket.send(text_response.encode(\"utf-8\"))\n",
    "                print(\"Text response sent.\")\n",
    "\n",
    "                # Step 2: Convert text response to speech and send the audio file\n",
    "                audio_file = synthesize_speech(text_response, output_file=\"response.wav\")\n",
    "                if audio_file:\n",
    "                    # Inform the client that audio is being sent\n",
    "                    client_socket.send(b\"AUDIO_INCOMING\")\n",
    "                    print(\"Notifying client about incoming audio.\")\n",
    "\n",
    "                    # Send the audio file content to the client\n",
    "                    with open(audio_file, \"rb\") as f:\n",
    "                        audio_data = f.read()\n",
    "                        client_socket.sendall(audio_data)\n",
    "                        print(\"Audio response sent.\")\n",
    "                else:\n",
    "                    client_socket.send(b\"Error generating audio.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during communication: {e}\")\n",
    "        finally:\n",
    "            client_socket.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"DatasetNLP.pdf\"  # Replace with your actual PDF file path\n",
    "    start_server(pdf_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
